{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Word Embeddings\n",
        "\n",
        "In this exercise, we'll load a set of pre-trained word embeddings created with `gensim` and use them to explore similarity.\n",
        "\nLet's start by importing the `gensim` module and loading our pre-trained embeddings."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\nw2v_embeddings = gensim.models.Word2Vec.load('wsj-embeddings.w2v')"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it! We can do a few operations on the embeddings, such as getting the number of words in the vocabulary."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(w2v_embeddings.wv.vocab))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44377\n"
          ]
        }
      ],
      "execution_count": 60,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Embeddings for Similarity\n",
        "\n",
        "More importantly, however, particularly for the purposes of the homework, we want to use our word embeddings to calculate similarities between words.\n",
        "\n",
        "Using the `gensim.models.Word2Vec` class, we can simply call:\n",
        "\n",
        "    w2v_embeddings.wv.simiarity(word_1, word_2)\n",
        "    \n",
        "To get the cosine similarity score between the vectors ([documentation here](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similarity))."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def print_similarity(word_1, word_2):\n",
        "    \n",
        "    def check_word(word):\n",
        "        contained = word in w2v_embeddings.wv\n",
        "        if not contained:\n",
        "            print('\"{}\" not seen in embeddings.'.format(word))\n",
        "        return contained\n",
        "        \n",
        "    if check_word(word_1) and check_word(word_2):\n",
        "        sim = w2v_embeddings.wv.similarity(word_1, word_2)\n",
        "        print('{:<18}  {:<15} = {}'.format(word_1, word_2, sim))\n",
        "\n",
        "print_similarity('man', 'woman')\n",
        "print_similarity('person', 'child')\n",
        "print_similarity('tax', 'money')\n",
        "print_similarity('tax', 'tariff')\n",
        "print_similarity('tax', 'savings')\n",
        "print_similarity('tax', 'dogs')\n",
        "print_similarity('pope', 'catholic')\n",
        "print_similarity('pope', 'senator')\n",
        "print_similarity('pope', 'leader')\n",
        "print_similarity('pope', 'tax')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man                 woman           = 0.9413719773292542\n",
            "person              child           = 0.8452761173248291\n",
            "tax                 money           = 0.6546809673309326\n",
            "tax                 tariff          = 0.6185605525970459\n",
            "tax                 savings         = 0.47217410802841187\n",
            "tax                 dogs            = 0.43527430295944214\n",
            "pope                catholic        = 0.8322218656539917\n",
            "pope                senator         = 0.8930568695068359\n",
            "pope                leader          = 0.8474855422973633\n",
            "pope                tax             = 0.1644563525915146\n"
          ]
        }
      ],
      "execution_count": 61,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlating with Human Judgments\n",
        "\nNow, I've designed a short in-class poll for us to go through a number of word pairs and get judgments from the class. We can use these results as a convenience sample of human judgments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "human_judgments = '''man,woman,5.0\n",
        "person,child,5.0\n",
        "tax,tariff,5.0\n",
        "tax,money,4.0\n",
        "tax,savings,3.0\n",
        "tax,dogs,1.0\n",
        "pope,catholic,4.0\n",
        "pope,senator,3.0\n",
        "pope,leader,3.0\n",
        "pope,tax,1.0\n",
        "'''\n",
        "\n",
        "import csv\n",
        "judgments = [(row[0], row[1], float(row[2])) for row in csv.reader(human_judgments.split('\\n')) if row]"
      ],
      "outputs": [],
      "execution_count": 62,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our human judgments obtained, let's use the human scores as array $a$ and the embeddings scores as array $b$, and use [`scipy.stats.spearmanr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to calculate the Spearman rank-order correlation coefficient."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "human_scores = [entry[2] for entry in judgments]\n",
        "embedding_scores = [w2v_embeddings.wv.similarity(w1, w2) for w1, w2, score in judgments]\n",
        "\n",
        "from scipy.stats.stats import spearmanr\n",
        "\nprint(spearmanr(human_scores, embedding_scores).correlation)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5315095895586142\n"
          ]
        }
      ],
      "execution_count": 67,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}